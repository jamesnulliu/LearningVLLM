from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langchain_core.messages import HumanMessage, SystemMessage

# ==========================================
# 1. å®šä¹‰å·¥å…· (Tools)
# ä½¿ç”¨ @tool è£…é¥°å™¨ï¼ŒLangChain ä¼šè‡ªåŠ¨æå–å‡½æ•°åã€å‚æ•°ç±»å‹å’Œ docstring ä½œä¸ºå·¥å…·æè¿°
# ==========================================

@tool
def google_search(query: str) -> str:
    """
    å½“ç”¨æˆ·è¯¢é—®æ—¶äº‹æ–°é—»ã€å¤©æ°”ã€æˆ–è€…ä¸–ç•Œä¸Šçš„é€šç”¨çŸ¥è¯†æ—¶ï¼Œä½¿ç”¨æ­¤å·¥å…·æœç´¢ Googleã€‚
    """
    # è¿™é‡Œæ¨¡æ‹ŸçœŸå®çš„æœç´¢ï¼Œå®é™…åº”ç”¨ä¸­å¯ä»¥è°ƒç”¨ Serper æˆ– Google API
    print(f"\n[Tool Called] æ­£åœ¨è°ƒç”¨ Google Search... æŸ¥è¯¢: {query}")
    if "å¤©æ°”" in query:
        return "Google æœç´¢ç»“æœ: ä»Šå¤©æ—§é‡‘å±±å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸© 20 æ‘„æ°åº¦ã€‚"
    return "Google æœç´¢ç»“æœ: Llama 3 æ˜¯ Meta å‘å¸ƒçš„æœ€æ–°çš„å¼€æºå¤§è¯­è¨€æ¨¡å‹ã€‚"

@tool
def read_local_file(filename: str) -> str:
    """
    å½“ç”¨æˆ·è¯¢é—®å…³äº'å†…éƒ¨ä¼šè®®'ã€'ç§æœ‰æ–‡æ¡£'ã€'é¡¹ç›®ä»£ç 'æ—¶ï¼Œä½¿ç”¨æ­¤å·¥å…·è¯»å–æœ¬åœ°æ–‡ä»¶ã€‚
    """
    print(f"\n[Tool Called] æ­£åœ¨è¯»å–æœ¬åœ°æ–‡ä»¶... æ–‡ä»¶å: {filename}")
    # æ¨¡æ‹Ÿè¯»å–æ–‡ä»¶
    return f"æ–‡ä»¶ '{filename}' çš„å†…å®¹æ˜¯ï¼šä¸‹å‘¨ä¸€ä¸Šåˆ 9 ç‚¹è¿›è¡Œå…¨å‘˜æŠ€æœ¯ä»£ç å®¡æŸ¥ã€‚"

# å°†å·¥å…·æ”¾å…¥åˆ—è¡¨
tools = [google_search, read_local_file]

# ==========================================
# 2. åˆå§‹åŒ–æœ¬åœ° Llama 3 (é€šè¿‡ LangChain çš„ ChatOpenAI)
# å…³é”®ç‚¹ï¼šbase_url æŒ‡å‘ vLLM çš„åœ°å€
# ==========================================

llm = ChatOpenAI(
    model="llama3",  # å¯¹åº” vLLM å¯åŠ¨æ—¶çš„ --served-model-name
    openai_api_key="token-123",
    openai_api_base="http://localhost:8000/v1", # vLLM çš„åœ°å€
    temperature=0
)

# ==========================================
# 3. ç»‘å®šå·¥å…· (Tool Binding)
# è¿™æ­¥æ“ä½œä¼šæŠŠå·¥å…·çš„ JSON Schema æ³¨å…¥åˆ° Llama 3 çš„ç³»ç»Ÿæç¤ºè¯ä¸­
# ==========================================

llm_with_tools = llm.bind_tools(tools)

# ==========================================
# 4. æµ‹è¯•åœºæ™¯
# ==========================================

def run_agent(user_query):
    print(f"\n{'='*10} ç”¨æˆ·æé—®: {user_query} {'='*10}")
    
    messages = [HumanMessage(content=user_query)]
    
    # è®© Llama 3 æ€è€ƒå¹¶å†³å®š
    ai_msg = llm_with_tools.invoke(messages)
    
    # æ£€æŸ¥ AI æ˜¯å¦å†³å®šè°ƒç”¨å·¥å…·
    if ai_msg.tool_calls:
        print(f"ğŸ‘‰ AI å†³å®šè°ƒç”¨å·¥å…·: {ai_msg.tool_calls[0]['name']}")
        print(f"ğŸ‘‰ å‚æ•°: {ai_msg.tool_calls[0]['args']}")
        
        # --- åœ¨çœŸå®çš„ Agent å¾ªç¯ä¸­ï¼Œè¿™é‡Œä¼šæ‰§è¡Œå·¥å…·å¹¶å°†ç»“æœè¿”å›ç»™ LLM ---
        # --- è¿™é‡Œä¸ºäº†æ¼”ç¤ºæ¸…æ™°ï¼Œæˆ‘ä»¬åªå±•ç¤ºåˆ°"å†³ç­–"è¿™ä¸€æ­¥ ---
    else:
        print("ğŸ‘‰ AI å†³å®šç›´æ¥å›ç­” (ä¸ä½¿ç”¨å·¥å…·)")
        print(f"å›ç­”: {ai_msg.content}")

# --- æµ‹è¯• 1: åº”è¯¥è§¦å‘ Google ---
run_agent("ä»Šå¤©æ—§é‡‘å±±å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")

# --- æµ‹è¯• 2: åº”è¯¥è§¦å‘æœ¬åœ°æ–‡ä»¶ ---
run_agent("å¸®æˆ‘æŸ¥ä¸€ä¸‹å†…éƒ¨ä¼šè®®è®°å½•é‡Œä¸‹å‘¨ä¸€æœ‰ä»€ä¹ˆå®‰æ’ï¼Ÿ")

# --- æµ‹è¯• 3: é€šç”¨èŠå¤© ---
run_agent("ä½ å¥½ï¼Œè®²ä¸ªç¬‘è¯ã€‚")